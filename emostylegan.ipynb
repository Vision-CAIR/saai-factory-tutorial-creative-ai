{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emostylegan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2BHrWBOA2Zi"
      },
      "source": [
        "Setup Enviroment and Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VVICTCvd4mc"
      },
      "source": [
        "!nvidia-smi -L\n",
        "\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jBpKxRD26AY"
      },
      "source": [
        "!pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "\n",
        "!pip3 install opensimplex click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
        "\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVB6ybPb0Tq-"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/stylegan2-ada-pytorch')\n",
        "emotions_dict = {\n",
        "    \"amusement\": 0,\n",
        "    \"anger\": 1,\n",
        "    \"awe\": 2,\n",
        "    \"contentmennt\": 3,\n",
        "    \"disgust\": 4,\n",
        "    \"excitement\": 5,\n",
        "    \"fear\": 6,\n",
        "    \"sadness\": 7\n",
        "}\n",
        "import os\n",
        "import re\n",
        "from typing import List, Optional, Any\n",
        "import click\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "!rm -rf sample_data/\n",
        "!gdown --id '1N_6fsmF2FfWyCowvMFSsWnfOnRMxnwb4'\n",
        "'''!gdown --id '1GvgdIldjMGV48JE5TGWjtdpGykTsuJ_L'\n",
        "!unzip '/content/utils.zip'\n",
        "!rm -rf __MACOSX/\n",
        "!rm -rf utils.zip\n",
        "'''\n",
        "import dnnlib\n",
        "import legacy\n",
        "emostylegan_model = '/content/network-snapshot-025000.pkl'\n",
        "outdir = '/content/image_generation'\n",
        "seed = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFZv7CmIA0gc"
      },
      "source": [
        "Functions to be used to generate image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfCZ9gJc0o0n"
      },
      "source": [
        "def num_range(s: str) -> List[int]:\n",
        "    '''Accept either a comma separated list of numbers 'a,b,c' or a range 'a-c' and return as a list of ints.'''\n",
        "\n",
        "    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
        "    m = range_re.match(s)\n",
        "    if m:\n",
        "        return list(range(int(m.group(1)), int(m.group(2))+1))\n",
        "    vals = s.split(',')\n",
        "    return [int(x) for x in vals]\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOhJAF6B09da"
      },
      "source": [
        "def generate_images(\n",
        "    network_pkl: str,\n",
        "    seeds: Optional[List[int]],\n",
        "    truncation_psi: float,\n",
        "    outdir: str,\n",
        "    class_idx: Optional[int],\n",
        "    emotion: str,\n",
        "):\n",
        "  \n",
        "  print('Loading networks from \"%s\"...' % network_pkl)\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl) as f:\n",
        "      G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "  os.makedirs(outdir, exist_ok=True)\n",
        "   # Labels.\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "  if G.c_dim != 0:\n",
        "      label[:, class_idx] = 1\n",
        "  else:\n",
        "      if class_idx is not None:\n",
        "        print ('warn: --class=lbl ignored when running on an unconditional network')\n",
        "\n",
        "  # Generate images.\n",
        "  for seed_idx, seed in enumerate(seeds):\n",
        "      print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n",
        "      z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device)\n",
        "      img = G(z, label, truncation_psi=truncation_psi)\n",
        "      img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "      PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}_{emotion}.png')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHGQZ0ZNURha"
      },
      "source": [
        "Generate and Display the Image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDtkugyfPlIQ"
      },
      "source": [
        "#----------------------------------------------------------------------------\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "emotions = 'awe' # Change this to any emotion from this list: amusement, anger, awe, contentment, disgust, excitement, fear, sadness\n",
        "trunc = 0.8 # Change 0.8 to be any truncation you'd like.\n",
        "\n",
        "generate_images(emostylegan_model, [seed], trunc, outdir, emotions_dict[emotions], emotions) # pylint: disable=no-value-for-parameter\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize =(10, 10))\n",
        "ax.imshow(Image.open(os.path.join(outdir, f'seed{str(seed).zfill(4)}_{emotions}.png')))\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}